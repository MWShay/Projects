{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FhzDExbrNJ2i"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO-_sjS7vMvQ",
        "outputId": "a1487619-10b0-490a-a520-216d4e3340c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "Device found : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import *\n",
        "import json\n",
        "import cv2\n",
        "import h5py\n",
        "import imageio\n",
        "from IPython.display import Image\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    Dropout,\n",
        "    MaxPooling2D,\n",
        "    UpSampling2D,\n",
        "    concatenate\n",
        ")\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "physical_device = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(f'Device found : {physical_device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "O90rXW_ovVLb",
        "outputId": "76266122-5529-4ab5-c324-da9403546f99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Volumes/MX500_1TB/GitHub/Projects/TEM_seg'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pKqFIuKOvca9"
      },
      "outputs": [],
      "source": [
        "# set home directory and data directory\n",
        "HOME_DIR = \"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/\"\n",
        "IMG_DIR = \"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/img/\"\n",
        "MSK_DIR = \"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/msk/\"\n",
        "\n",
        "#Data Augmentation Path\n",
        "AUG_DIR = \"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/aug/\"\n",
        "\n",
        "SUB_DIR = \"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/sub_img/\"\n",
        "TRAIN_DATA_DIR = \"\"\n",
        "VALID_DATA_DIR = \"\"\n",
        "TEST_DATA_DIR = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkCJmGuTN3uE"
      },
      "source": [
        "# Encoder(DownSampling) Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dCDEHRH5N3EK"
      },
      "outputs": [],
      "source": [
        "def conv_block(inputs = None, n_filters = 32, dropout_prob = 0, max_pooling = True):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "    Convolutional downsampling block\n",
        "\n",
        "    Arguments:\n",
        "        inputs -- Input tensor\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        dropout_prob -- Dropout probability\n",
        "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
        "    Returns:\n",
        "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
        "  \"\"\"\n",
        "\n",
        "  conv = Conv2D(filters = n_filters,\n",
        "                kernel_size = 3,\n",
        "                activation = 'relu',\n",
        "                padding = 'same',\n",
        "                kernel_initializer = 'he_normal')(inputs)\n",
        "\n",
        "  conv = Conv2D(filters = n_filters,\n",
        "                kernel_size = 3,\n",
        "                activation = 'relu',\n",
        "                padding = 'same',\n",
        "                kernel_initializer = 'he_normal')(conv)\n",
        "\n",
        "  # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
        "  if dropout_prob > 0:\n",
        "    conv = Dropout(dropout_prob)(conv)\n",
        "\n",
        "  # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
        "  if max_pooling:\n",
        "    next_layer = MaxPooling2D(2, strides = 2)(conv)\n",
        "\n",
        "  else:\n",
        "    next_layer = conv\n",
        "\n",
        "  skip_connection = conv\n",
        "\n",
        "  return next_layer, skip_connection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNGotClqa0n2"
      },
      "source": [
        "# Decoder(UpSampling) Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "3ZJEouUBRSbE"
      },
      "outputs": [],
      "source": [
        "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
        "  \"\"\"\n",
        "    Convolutional upsampling block\n",
        "\n",
        "    Arguments:\n",
        "        expansive_input -- Input tensor from previous layer\n",
        "        contractive_input -- Input tensor from previous skip layer\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "    Returns:\n",
        "        conv -- Tensor output\n",
        "  \"\"\"\n",
        "\n",
        "    ### START CODE HERE\n",
        "  up = Conv2DTranspose(filters = n_filters,\n",
        "                       kernel_size = 3,\n",
        "                       strides=2,\n",
        "                       padding='same')(expansive_input)\n",
        "\n",
        "    # Merge the previous output and the contractive_input\n",
        "  #merge = concatenate([up, contractive_input], axis=3)\n",
        "  merge = concatenate([up, contractive_input], axis=1)\n",
        "  conv = Conv2D(filters = n_filters,\n",
        "                kernel_size = 3,\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal')(merge)\n",
        "  conv = Conv2D(filters = n_filters,\n",
        "                kernel_size = 3,\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal')(conv)\n",
        "\n",
        "  return conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UNET Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def unet_model(input_size=(256, 256, 1), n_filters=32, n_classes=1):\n",
        "    \"\"\" \n",
        "    Unet model\n",
        "    \n",
        "    Arguments:\n",
        "        input_size -- Input shape \n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        n_classes -- Number of output classes\n",
        "    Returns: \n",
        "        model -- tf.keras.Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    # Contracting Path (encoding)\n",
        "    # Add a conv_block with the inputs of the unet_ model and n_filters\n",
        "    cblock1 = conv_block(inputs=inputs, n_filters=n_filters*1)\n",
        "    # Chain the first element of the output of each block to be the input of the next conv_block. \n",
        "    # Double the number of filters at each new step\n",
        "    cblock2 = conv_block(inputs=cblock1[0], n_filters=n_filters*2)\n",
        "    cblock3 = conv_block(inputs=cblock2[0], n_filters=n_filters*4)\n",
        "    cblock4 = conv_block(inputs=cblock3[0], n_filters=n_filters*8,dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "    # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
        "    cblock5 = conv_block(inputs=cblock4[0], n_filters=n_filters*16,dropout_prob=0.3, max_pooling=False) \n",
        "    \n",
        "    # Expanding Path (decoding)\n",
        "    # Add the first upsampling_block.\n",
        "    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
        "    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters*8)\n",
        "    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n",
        "    # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n",
        "    # At each step, use half the number of filters of the previous block \n",
        "    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters*4)\n",
        "    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters*2)\n",
        "    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters*1)\n",
        "\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 # set 'kernel_initializer' same as above exercises\n",
        "                 kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
        "    ### START CODE HERE\n",
        "    #conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
        "    conv10 = Conv2D(filters = 1, kernel_size = 1, data_format = 'channels_first',activation='sigmoid')(conv9)\n",
        "    ### END CODE HERE\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "unet= unet_model(input_size=(1, 256, 256), n_filters=32, n_classes=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None, 1, 256, 256  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_303 (Conv2D)            (None, 32, 256, 256  320         ['input_18[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_304 (Conv2D)            (None, 32, 256, 256  9248        ['conv2d_303[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_62 (MaxPooling2D  (None, 32, 128, 128  0          ['conv2d_304[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_305 (Conv2D)            (None, 64, 128, 128  18496       ['max_pooling2d_62[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_306 (Conv2D)            (None, 64, 128, 128  36928       ['conv2d_305[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_63 (MaxPooling2D  (None, 64, 64, 64)  0           ['conv2d_306[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_307 (Conv2D)            (None, 128, 64, 64)  73856       ['max_pooling2d_63[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_308 (Conv2D)            (None, 128, 64, 64)  147584      ['conv2d_307[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_64 (MaxPooling2D  (None, 128, 32, 32)  0          ['conv2d_308[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_309 (Conv2D)            (None, 256, 32, 32)  295168      ['max_pooling2d_64[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_310 (Conv2D)            (None, 256, 32, 32)  590080      ['conv2d_309[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 256, 32, 32)  0           ['conv2d_310[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_65 (MaxPooling2D  (None, 256, 16, 16)  0          ['dropout_30[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_311 (Conv2D)            (None, 512, 16, 16)  1180160     ['max_pooling2d_65[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_312 (Conv2D)            (None, 512, 16, 16)  2359808     ['conv2d_311[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)           (None, 512, 16, 16)  0           ['conv2d_312[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_60 (Conv2DTra  (None, 256, 32, 32)  1179904    ['dropout_31[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenate)   (None, 512, 32, 32)  0           ['conv2d_transpose_60[0][0]',    \n",
            "                                                                  'dropout_30[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_313 (Conv2D)            (None, 256, 32, 32)  1179904     ['concatenate_60[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_314 (Conv2D)            (None, 256, 32, 32)  590080      ['conv2d_313[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_61 (Conv2DTra  (None, 128, 64, 64)  295040     ['conv2d_314[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenate)   (None, 256, 64, 64)  0           ['conv2d_transpose_61[0][0]',    \n",
            "                                                                  'conv2d_308[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_315 (Conv2D)            (None, 128, 64, 64)  295040      ['concatenate_61[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_316 (Conv2D)            (None, 128, 64, 64)  147584      ['conv2d_315[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_62 (Conv2DTra  (None, 64, 128, 128  73792      ['conv2d_316[0][0]']             \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenate)   (None, 128, 128, 12  0           ['conv2d_transpose_62[0][0]',    \n",
            "                                8)                                'conv2d_306[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_317 (Conv2D)            (None, 64, 128, 128  73792       ['concatenate_62[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_318 (Conv2D)            (None, 64, 128, 128  36928       ['conv2d_317[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_63 (Conv2DTra  (None, 32, 256, 256  18464      ['conv2d_318[0][0]']             \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_63 (Concatenate)   (None, 64, 256, 256  0           ['conv2d_transpose_63[0][0]',    \n",
            "                                )                                 'conv2d_304[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_319 (Conv2D)            (None, 32, 256, 256  18464       ['concatenate_63[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_320 (Conv2D)            (None, 32, 256, 256  9248        ['conv2d_319[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_321 (Conv2D)            (None, 32, 256, 256  9248        ['conv2d_320[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_322 (Conv2D)            (None, 1, 256, 256)  33          ['conv2d_321[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,639,169\n",
            "Trainable params: 8,639,169\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "unet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "unet.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['BinaryIoU'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the trained Model/Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "Weights_DIR = HOME_DIR + \"\"\n",
        "Weights =unet.load_weights(Weights_DIR + filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the test set files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"\"\n",
        "folder_path = \"\"\n",
        "image = imageio.imread(folder_path + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_x = 1024\n",
        "orig_y = 1024\n",
        "\n",
        "step_x = 128\n",
        "step_y = 128\n",
        "\n",
        "output_x = 256\n",
        "output_y = 256\n",
        "\n",
        "seq=[]\n",
        "\n",
        "img=np.array(imageio.imread(IMG_DIR + IMG_list[i]))\n",
        "msk=np.array(imageio.imread(MSK_DIR + MSK_list[i]))\n",
        "img_scale=scaler.fit_transform(img.reshape(-1, 1)).reshape(img.shape)\n",
        "\n",
        "for x in range(0, orig_x-output_x+1, step_x):\n",
        "    for y in range(0, orig_y-output_y+1, step_y):\n",
        "\n",
        "            start_x = x\n",
        "            start_y = y\n",
        "\n",
        "            X = np.copy(img_scale[start_x: start_x + output_x,\n",
        "                                  start_y: start_y + output_y])\n",
        "            Y = np.copy(msk[start_x: start_x + output_x,\n",
        "                                start_y: start_y + output_y])\n",
        "\n",
        "            file=filename \\\n",
        "            +\"_x_\"+str(start_x) \\\n",
        "            +\"_y_\"+str(start_y) \\\n",
        "            +\"_.h5\"\n",
        "\n",
        "            seq.append(file)\n",
        "\n",
        "print(len(seq))\n",
        "for i in range(len(seq)):\n",
        "    print(seq[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_x = 1024\n",
        "orig_y = 1024\n",
        "\n",
        "step_x = 128\n",
        "step_y = 128\n",
        "\n",
        "output_x = 256\n",
        "output_y = 256\n",
        "num_classes = 2\n",
        "\n",
        "for i in range(0, len(IMG_list)):\n",
        "    filename = IMG_list[i]\n",
        "    img=np.array(imageio.imread(IMG_DIR + IMG_list[i]))\n",
        "    \n",
        "    msk=np.array(imageio.imread(MSK_DIR + MSK_list[i]))\n",
        "    img_scale=scaler.fit_transform(img.reshape(-1, 1)).reshape(img.shape)\n",
        "\n",
        "    # Initialize features and labels with `None`\n",
        "    X = None\n",
        "    Y = None\n",
        "\n",
        "    for x in range(0, orig_x-output_x+1, step_x):\n",
        "        for y in range(0, orig_y-output_y+1, step_y):\n",
        "\n",
        "                start_x = x\n",
        "                start_y = y\n",
        "\n",
        "                Y = np.copy(msk[start_x: start_x + output_x,\n",
        "                                start_y: start_y + output_y])\n",
        "                #Y = keras.utils.to_categorical(Y, num_classes=num_classes)\n",
        "\n",
        "                X = np.copy(img_scale[start_x: start_x + output_x,\n",
        "                                start_y: start_y + output_y])\n",
        "\n",
        "                    # change dimension of X\n",
        "                    # from (x_dim, y_dim, z_dim, num_channels)\n",
        "                    # to (num_channels, x_dim, y_dim, z_dim)\n",
        "                X = np.expand_dims(X, axis=0)\n",
        "                Y = np.expand_dims(Y, axis=0)\n",
        "\n",
        "                    # change dimension of y\n",
        "                    # from (x_dim, y_dim, z_dim, num_classes)\n",
        "                    # to (num_classes, x_dim, y_dim, z_dim)\n",
        "                #Y = np.moveaxis(Y, 3, 0)\n",
        "\n",
        "                    #excludes the background class\n",
        "                #Y = Y[:, :, :]\n",
        "\n",
        "                file=filename \\\n",
        "                +\"_x_\"+str(start_x) \\\n",
        "                +\"_y_\"+str(start_y) \\\n",
        "                +\"_\"\n",
        "\n",
        "                destination = os.path.join(\"/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/sub_img/\", f\"{file}.h5\")\n",
        "\n",
        "                if os.path.exists(destination):\n",
        "                    # File already exists, do something\n",
        "                    pass\n",
        "\n",
        "                else:\n",
        "                    os.makedirs(os.path.dirname(destination), exist_ok= True)\n",
        "                    with h5py.File(destination, \"w\") as f1:\n",
        "                        dset1 = f1.create_dataset(\"x\", (output_x, output_y), dtype='float32', data=X)\n",
        "                        dset2 = f1.create_dataset(\"y\", (output_x, output_y), dtype='uint8', data=Y)\n",
        "                        f1.close()\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Volumes/MX500_1TB/DataSet/BF-TEM/CJL_lab/data_train/sub_img/\n",
            "(98, 1, 256, 256)\n",
            "(98, 1, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "num_channels = 1\n",
        "num_classes = 1\n",
        "dim = (256, 256)\n",
        "X_train = np.zeros((len(config[\"train\"]), num_channels, *dim),\n",
        "             dtype=np.float64) #float64\n",
        "y_train = np.zeros((len(config[\"train\"]), num_classes, *dim),\n",
        "             dtype=np.float64) #float64\n",
        "# Generate data\n",
        "\n",
        "#base_dir = \"./BraTS-Data/processed/\"\n",
        "directory_train = base_dir + \"sub_img/\"\n",
        "print(directory_train)\n",
        "\n",
        "for i,ID in enumerate(config[\"train\"]):\n",
        "    # Store sample\n",
        "    with h5py.File(directory_train + ID, 'r') as f:\n",
        "        X_train[i] = np.array(f.get(\"x\"))\n",
        "        y_train[i] = np.array(f.get(\"y\"))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function to define axis corrdianation in image reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def axis_subimage(axis, origin, step, output):\n",
        "    if axis == 0:\n",
        "        start_coord = axis\n",
        "        end_coord = output - step/2\n",
        "    elif axis == (origin - output):\n",
        "        start_coord = step/2\n",
        "        end_coord = output\n",
        "    else:\n",
        "        start_coord = step/2\n",
        "        end_coord = output - step/2\n",
        "\n",
        "    return int(start_coord), int(end_coord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def axis_coord(axis, orig, step, output):\n",
        "    if axis == 0:\n",
        "        start_coord = axis\n",
        "        end_coord = axis + output - step/2 \n",
        "    elif axis == (orig - output):\n",
        "        start_coord = axis + step/2\n",
        "        end_coord = axis + output \n",
        "    else:\n",
        "        start_coord = axis + step/2\n",
        "        end_coord = axis + output -step/2 \n",
        "\n",
        "    return int(start_coord), int(end_coord)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test coordination code section, don't need to run when reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_label = np.zeros((125, 80, 80, 64))\n",
        "i=0\n",
        "for file in seq:\n",
        "    filepath = Test_DIR + file\n",
        "    with h5py.File(filepath, 'r') as f:\n",
        "        img = np.array(f.get(\"x\"))\n",
        "        msk = np.array(f.get(\"y\"))\n",
        "    \n",
        "    # create the background volume with all 0s\n",
        "    background = np.zeros((1, 80, 80, 64))\n",
        "    \n",
        "    \n",
        "    mask = np.concatenate((background, msk), axis=0)\n",
        "    label_3D = np.argmax(mask, axis = 0)\n",
        "\n",
        "    orig_label[i, :, :, :] = label_3D\n",
        "    \n",
        "    i += 1\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_x = 512\n",
        "orig_y = 512\n",
        "\n",
        "step_x = 40\n",
        "step_y = 40\n",
        "\n",
        "output_x = 80\n",
        "output_y = 80\n",
        "\n",
        "print(seq)\n",
        "\n",
        "i = np.random.randint(0, 124)\n",
        "i=124\n",
        "ax_x = int(seq[i].split(\"_\")[3])\n",
        "ax_y = int(seq[i].split(\"_\")[5])\n",
        "ax_z = int(seq[i].split(\"_\")[7])\n",
        "\n",
        "start_x, end_x = axis_coord(ax_x, orig_x, step_x, output_x)\n",
        "start_y, end_y = axis_coord(ax_y, orig_y, step_y, output_y)\n",
        "\n",
        "V_start_x, V_end_x = axis_subimage(ax_x, orig_x, step_x, output_x)\n",
        "V_start_y, V_end_y = axis_subimage(ax_y, orig_y, step_y, output_y)\n",
        "\n",
        "print(ax_x)\n",
        "print(ax_y)\n",
        "\n",
        "print(seq[i])\n",
        "print(f\"start_x is: {start_x}, end_x is : {end_x}\" )\n",
        "print(f\"start_y is: {start_y}, end_y is : {end_y}\" )\n",
        "\n",
        "print(f\"image start_x is: {V_start_x}, image end_x is : {V_end_x}, length is : {(V_end_x-V_start_x+1)}\" )\n",
        "print(f\"image start_y is: {V_start_y}, image end_y is : {V_end_y}, length is : {(V_end_y-V_start_y+1)}\" )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
